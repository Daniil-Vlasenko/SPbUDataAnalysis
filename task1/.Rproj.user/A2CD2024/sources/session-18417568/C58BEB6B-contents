---
title: "task1"
output: html_document
date: "2023-03-13"
---

```{r, message=FALSE}
library(readxl)
library(dplyr)
```

```{r}
df <- read_xls("PRESTIGE (1).xls")
head(df)
```

Построим линейную регрессионную модель. Хотим узнать как престиж, доходы и 
образованность влияют на суицидальность.
```{r}
model = lm(SUICIDE~PRESTIGE+INCOME+SCHOOL, data=df)
summary(model)
```

Столбец Estimate демонстрирует, что чем ниже уровень образования, тем выше 
суицидальность, остальные два признака кажутся незначимыми. Столбец Pr(>|t|) 
отражает p-value проверки гипотезы незначивомисти признаков в модели. С увровнем
значимости 0.5 только SCHOOL значим.

F-statistic p-value меньше 0.5, модель значима.

Теперь стандартизируем коэффициенты регрессии.
```{r}
library(lm.beta)
model.s <- lm.beta(model)
summary(model.s)
```

Появляется новый столбец Standardized.

Тут нужно будет порисовать что-то.
Посмотрим на корреляционную матрицу между коэффициентами модели.
```{r}
cov2cor(vcov(model.s))
```

```{r}
library(plotrix)
plot(c(-5,5), c(-5,5), type="n", main="test draw.ellipse")
draw.ellipse(x=0, y=0, a = 1, b = 1, angle = 0)
```

## 3.
Попробуем в ручную уменьшить число признаков, исходя из изученных характеристик.

Вычислим Tolerance.
[R - множественный коэффициент корреляции;
Tolerance = 1 + R^2;
VIF = 1 / (1 + R^2) = 1 / Tolerance.]
```{r}
library(olsrr)
ols_vif_tol(model)
```
Меньшее значние Tolerance у престижности професии.

Вычислим частные корреляции.
[Zero Order - корреляция Пирсона между зависимой и независимой переменными;
Partial - частная корреляци между;
Part - получастная корреляция.]
```{r}
ols_correlations(model)
```

Большая частная корреляция у SCHOOL, т.е. менее предпочтительно ее исключать.
